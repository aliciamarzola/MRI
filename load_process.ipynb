{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddce3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nibabel.processing import resample_to_output\n",
    "from skimage.transform import resize\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from nilearn.masking import compute_brain_mask\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b92c2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MODALITY = 't1c'\n",
    "TARGET_MODALITY = 't2w'\n",
    "NEW_SHAPE = (128, 128, 128)  # ajustar se quiser preservar resolução original\n",
    "VOXEL_SIZE = (1.0, 1.0, 1.0)  # mm³ padrão BraTS\n",
    "DATASET_DIR = '}datasets/brats/training_data'  # pasta onde estão as subpastas dos pacientes\n",
    "SAVE_PATH = 'dataset_t1c_to_t2w.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cd194e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(path):\n",
    "\n",
    "    \"\"\"Carrega e reorienta uma imagem NIfTI para o espaço canônico (RAS+).\n",
    "    Garante que todas as imagens tenham a mesma orientação espacial (alinhadas em relação aos mesmos eixos do cérebro)\"\"\"\n",
    "\n",
    "    img = nib.load(path)\n",
    "    img = nib.as_closest_canonical(img) #RAS = right, anterior, superior\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ed6721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(img, voxel_size=VOXEL_SIZE):\n",
    "    \"\"\"Padroniza o tamanho dos voxels em 1mm³. Isso garante que todas as imagens fiquem no mesmo espaço e escala, \n",
    "    o que é essencial para comparações, registros e aprendizado de máquina.\"\"\"\n",
    "    return resample_to_output(img, voxel_sizes=voxel_size)\n",
    "\n",
    "\n",
    "def nlmeans_and_normalize(data, patch_size=3, patch_distance=5, h_factor=1.0):\n",
    "    \"\"\"\n",
    "    Aplica denoising Non-Local Means (NLM) e normaliza a imagem.\n",
    "    \n",
    "    Parâmetros:\n",
    "        data: array numpy (3D MRI ou 2D imagem)\n",
    "        patch_size: tamanho do patch para comparar similaridades (ex: 3x3x3)\n",
    "        patch_distance: distância máxima para busca de patches similares\n",
    "        h_factor: fator de suavização (controla o peso do filtro)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estima o nível de ruído na imagem\n",
    "    sigma_est = np.mean(estimate_sigma(data, channel_axis=None))\n",
    "    \n",
    "    # Aplica Non-Local Means (NLM)\n",
    "    denoised = denoise_nl_means(\n",
    "        data,\n",
    "        h=h_factor * sigma_est,       # controla o quanto suaviza\n",
    "        patch_size=patch_size,\n",
    "        patch_distance=patch_distance,\n",
    "        channel_axis=None,            # MRI não tem canais RGB\n",
    "        fast_mode=True\n",
    "    )\n",
    "    \n",
    "    # Normaliza a intensidade com z-score\n",
    "    normed = (denoised - np.mean(denoised)) / (np.std(denoised) + 1e-8)\n",
    "    return normed\n",
    "\n",
    "\n",
    "def skull_strip(data):\n",
    "    \"\"\"\n",
    "    Gera uma máscara do cérebro usando nilearn.\n",
    "    Retorna a máscara binária (True = cérebro) e a imagem mascarada.\n",
    "    \"\"\"\n",
    "    temp_img = nib.Nifti1Image(data, affine=np.eye(4)) # objeto Nifti1Image temporário, necessário para nilearn\n",
    "    \n",
    "    # Calcula e aplica máscara do cérebro\n",
    "    brain_mask = compute_brain_mask(temp_img).get_fdata().astype(bool)\n",
    "    masked_data = np.where(brain_mask, data, 0)\n",
    "\n",
    "    return masked_data, brain_mask\n",
    "\n",
    "\n",
    "def crop_background_with_mask(data):\n",
    "    \"\"\"\n",
    "    Recorta a imagem baseado na máscara do cérebro.\n",
    "    Retorna o volume recortado e as coordenadas para reconstrução.\n",
    "    \"\"\"\n",
    "    masked_data, brain_mask = skull_strip(data)\n",
    "    coords = np.array(np.nonzero(brain_mask))\n",
    "    if coords.size == 0:\n",
    "        return masked_data, None  # máscara vazia\n",
    "    \n",
    "    minz, miny, minx = coords.min(axis=1)\n",
    "    maxz, maxy, maxx = coords.max(axis=1)\n",
    "    \n",
    "    cropped = masked_data[minz:maxz, miny:maxy, minx:maxx]\n",
    "    cropped_mask = brain_mask[minz:maxz, miny:maxy, minx:maxx]\n",
    "    \n",
    "    return cropped, cropped_mask, (minz, maxz, miny, maxy, minx, maxx)\n",
    "\n",
    "def resize_volume(img, new_shape=NEW_SHAPE):\n",
    "    \"\"\"Garante que todas as imagens tenham o mesmo tamanho.\n",
    "    - constant: completa valores desconhecidos com 0\n",
    "    - preserve_range: mantenha as intensidades originais\"\"\"\n",
    "    return resize(img, new_shape, mode='constant', preserve_range=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f0d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_patient(patient_dir):\n",
    "    \"\"\"\n",
    "    Carrega t1c (entrada) e t2w (alvo) de um paciente,\n",
    "    aplica o pipeline completo e retorna volumes prontos.\n",
    "    \"\"\"\n",
    "    pid = os.path.basename(patient_dir)\n",
    "    t1c_path = os.path.join(patient_dir, f\"{pid}-{INPUT_MODALITY}.nii.gz\")\n",
    "    t2w_path = os.path.join(patient_dir, f\"{pid}-{TARGET_MODALITY}.nii.gz\")\n",
    "\n",
    "    # Load + Reorient\n",
    "    img_in = load_nifti(t1c_path)\n",
    "    img_out = load_nifti(t2w_path)\n",
    "\n",
    "    # Resample para voxel uniforme\n",
    "    img_in = resample_image(img_in)\n",
    "    img_out = resample_image(img_out)\n",
    "\n",
    "    data_in = img_in.get_fdata()\n",
    "    data_out = img_out.get_fdata()\n",
    "\n",
    "    # Background removing (com coordenadas iguais)\n",
    "    cropped_in, _, bbox = crop_background_with_mask(data_in)\n",
    "    if bbox is None:\n",
    "        return None, None\n",
    "    minz, maxz, miny, maxy, minx, maxx = bbox\n",
    "    masked_data_out, _ = skull_strip(data_out)\n",
    "    cropped_out = masked_data_out[minz:maxz, miny:maxy, minx:maxx]\n",
    "\n",
    "    # NLM + Normalização\n",
    "    cropped_in = nlmeans_and_normalize(cropped_in)\n",
    "    cropped_out = nlmeans_and_normalize(cropped_out)\n",
    "\n",
    "    # Resize para shape fixo\n",
    "    cropped_in = resize_volume(cropped_in)\n",
    "    cropped_out = resize_volume(cropped_out)\n",
    "\n",
    "    return cropped_in, cropped_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46cf3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 350 pacientes.\n",
      "[1/350] Processando datasets/brats/training_data/BraTS-GLI-02405-100...\n",
      "[2/350] Processando datasets/brats/training_data/BraTS-GLI-02405-101...\n",
      "[3/350] Processando datasets/brats/training_data/BraTS-GLI-02406-100...\n",
      "[4/350] Processando datasets/brats/training_data/BraTS-GLI-02407-100...\n",
      "[5/350] Processando datasets/brats/training_data/BraTS-GLI-02408-100...\n",
      "[6/350] Processando datasets/brats/training_data/BraTS-GLI-02409-100...\n",
      "[7/350] Processando datasets/brats/training_data/BraTS-GLI-02410-100...\n",
      "[8/350] Processando datasets/brats/training_data/BraTS-GLI-02410-101...\n",
      "[9/350] Processando datasets/brats/training_data/BraTS-GLI-02411-100...\n",
      "[10/350] Processando datasets/brats/training_data/BraTS-GLI-02412-100...\n",
      "[11/350] Processando datasets/brats/training_data/BraTS-GLI-02413-100...\n",
      "[12/350] Processando datasets/brats/training_data/BraTS-GLI-02414-100...\n",
      "[13/350] Processando datasets/brats/training_data/BraTS-GLI-02415-100...\n",
      "[14/350] Processando datasets/brats/training_data/BraTS-GLI-02416-100...\n",
      "[15/350] Processando datasets/brats/training_data/BraTS-GLI-02417-100...\n",
      "[16/350] Processando datasets/brats/training_data/BraTS-GLI-02417-101...\n",
      "[17/350] Processando datasets/brats/training_data/BraTS-GLI-02418-100...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, p_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(patient_dirs):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(patient_dirs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Processando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     X, Y = \u001b[43mpreprocess_patient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m         X_list.append(X)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mpreprocess_patient\u001b[39m\u001b[34m(patient_dir)\u001b[39m\n\u001b[32m     27\u001b[39m cropped_out = masked_data_out[minz:maxz, miny:maxy, minx:maxx]\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# NLM + Normalização\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m cropped_in = \u001b[43mnlmeans_and_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m cropped_out = nlmeans_and_normalize(cropped_out)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Resize para shape fixo\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mnlmeans_and_normalize\u001b[39m\u001b[34m(data, patch_size, patch_distance, h_factor)\u001b[39m\n\u001b[32m     19\u001b[39m sigma_est = np.mean(estimate_sigma(data, channel_axis=\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Aplica Non-Local Means (NLM)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m denoised = \u001b[43mdenoise_nl_means\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_factor\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# controla o quanto suaviza\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatch_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatch_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# MRI não tem canais RGB\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Normaliza a intensidade com z-score\u001b[39;00m\n\u001b[32m     32\u001b[39m normed = (denoised - np.mean(denoised)) / (np.std(denoised) + \u001b[32m1e-8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/.venv/lib/python3.13/site-packages/skimage/_shared/utils.py:445\u001b[39m, in \u001b[36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    442\u001b[39m channel_axis = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mchannel_axis\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isscalar(channel_axis):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/.venv/lib/python3.13/site-packages/skimage/restoration/non_local_means.py:186\u001b[39m, in \u001b[36mdenoise_nl_means\u001b[39m\u001b[34m(image, patch_size, patch_distance, h, fast_mode, sigma, preserve_range, channel_axis)\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m4D requires fast_mode to be True.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m dn = np.asarray(\u001b[43mnlm_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_nl_means_denoising.pyx:936\u001b[39m, in \u001b[36mskimage.restoration._nl_means_denoising._fast_nl_means_denoising_3d\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/.venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:1617\u001b[39m, in \u001b[36m_squeeze_dispatcher\u001b[39m\u001b[34m(a, axis)\u001b[39m\n\u001b[32m   1612\u001b[39m     a = concatenate((a,) * repeats)[:new_size]\n\u001b[32m   1614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[32m-> \u001b[39m\u001b[32m1617\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_squeeze_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1618\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[32m   1621\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[32m   1622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X_list, Y_list = [], []\n",
    "\n",
    "patient_dirs = sorted(glob.glob(os.path.join(\"datasets/brats/training_data/BraTS-GLI-*\")))\n",
    "print(f\"Encontrados {len(patient_dirs)} pacientes.\")\n",
    "\n",
    "for i, p_dir in enumerate(patient_dirs):\n",
    "    print(f\"[{i+1}/{len(patient_dirs)}] Processando {p_dir}...\")\n",
    "    X, Y = preprocess_patient(p_dir)\n",
    "    if X is not None:\n",
    "        X_list.append(X)\n",
    "        Y_list.append(Y)\n",
    "\n",
    "X_all = np.stack(X_list, axis=0)\n",
    "Y_all = np.stack(Y_list, axis=0)\n",
    "print(\"Shape final:\")\n",
    "print(\"X:\", X_all.shape, \"Y:\", Y_all.shape)\n",
    "\n",
    "np.savez_compressed(SAVE_PATH, X=X_all, Y=Y_all)\n",
    "print(f\"Dataset salvo em {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683a1d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNome da GPU:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.get_device_name(\u001b[32m0\u001b[39m))\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Verifica se um tensor está na GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mO tensor está na GPU?\u001b[39m\u001b[33m\"\u001b[39m, x.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:410\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    414\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verifica se há GPU disponível\n",
    "print(\"GPU disponível:\", torch.cuda.is_available())\n",
    "\n",
    "# Nome da GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nome da GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Verifica se um tensor está na GPU\n",
    "x = torch.tensor([1.0, 2.0]).cuda()\n",
    "print(\"O tensor está na GPU?\", x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea594196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
